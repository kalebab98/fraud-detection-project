{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e07a00",
   "metadata": {},
   "source": [
    "# Task 3: Model Explainability with SHAP\n",
    "\n",
    "This notebook demonstrates training a fraud detection model using XGBoost with GPU acceleration, balancing the dataset with SMOTE, and interpreting model predictions using SHAP explainability techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5b706",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Import libraries\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde61c1",
   "metadata": {},
   "source": [
    "## Load Processed Data and Prepare Features\n",
    "\n",
    "- Load the processed fraud dataset.\n",
    "- Separate features (`X`) and target (`y`).\n",
    "- Split into train and test sets with stratification to keep class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b6383",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# âš™ï¸ Load processed data\n",
    "fraud_data = pd.read_csv('Fraud_Data.csv')\n",
    "\n",
    "# ðŸŽ¯ Separate features and target\n",
    "X = fraud_data.drop('class', axis=1)\n",
    "y = fraud_data['class']\n",
    "\n",
    "# ðŸ“Š Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ab8c8",
   "metadata": {},
   "source": [
    "## Convert datetime columns to numeric timestamps\n",
    "\n",
    "- Convert `signup_time` and `purchase_time` to datetime objects.\n",
    "- Then convert them to integer timestamps for model compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbff3b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List datetime columns that need conversion\n",
    "datetime_columns = ['signup_time', 'purchase_time']\n",
    "\n",
    "# Convert datetime columns to timestamps\n",
    "for col in datetime_columns:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = pd.to_datetime(X_train[col], errors='coerce')\n",
    "        X_test[col] = pd.to_datetime(X_test[col], errors='coerce')\n",
    "\n",
    "        # Convert to numeric timestamp (seconds since epoch)\n",
    "        X_train[col] = X_train[col].astype('int64') // 10**9\n",
    "        X_test[col] = X_test[col].astype('int64') // 10**9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf3e82",
   "metadata": {},
   "source": [
    "## Keep only numeric features for model training\n",
    "\n",
    "- Drop any non-numeric columns after conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7569731",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only numeric columns\n",
    "X_train = X_train.select_dtypes(include=['number'])\n",
    "X_test = X_test.select_dtypes(include=['number'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3895000",
   "metadata": {},
   "source": [
    "## Handle class imbalance by applying SMOTE to the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2d7a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Balance the data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7fd84",
   "metadata": {},
   "source": [
    "## Scale features using StandardScaler\n",
    "\n",
    "- Also, randomly sample 10,000 instances if dataset is large to speed up training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f16190",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Subsample if dataset too large\n",
    "sample_size = 10000\n",
    "if X_resampled.shape[0] > sample_size:\n",
    "    indices = np.random.choice(len(X_resampled), sample_size, replace=False)\n",
    "    X_resampled = X_resampled[indices]\n",
    "    y_resampled = y_resampled.iloc[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7d7f8",
   "metadata": {},
   "source": [
    "## Train the final model using XGBoost with GPU acceleration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774cc6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train the final model (XGBoost GPU)\n",
    "model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf12cc",
   "metadata": {},
   "source": [
    "## Interpret model predictions using SHAP\n",
    "\n",
    "- Generate SHAP values on a subset of test data.\n",
    "- Create summary, bar, force, and waterfall plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6324f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(model, X_resampled)\n",
    "\n",
    "# Calculate SHAP values for first 100 test samples\n",
    "shap_values = explainer(X_test_scaled[:100])\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100])\n",
    "\n",
    "# SHAP bar plot\n",
    "shap.plots.bar(shap_values)\n",
    "\n",
    "# SHAP force plot for a single prediction\n",
    "sample_index = 0\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[sample_index].values, X_test.iloc[sample_index])\n",
    "\n",
    "# SHAP waterfall plot for the same sample\n",
    "shap.plots.waterfall(shap_values[sample_index])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
